{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a5c4fbd6",
   "metadata": {},
   "source": [
    "#### This script predicts variables (like stomatal conductance, LE, T, etc.) using trained ipure ML model of stomatal conductnace under Configuration-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d671ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# SW_model_LE: calculate the LE using Shutteleworth-Wallace model given rsc and other input variable\n",
    "def SW_model_LE_np(auxi, rsc_pre):\n",
    "    \n",
    "    #---- SW-Model ----\n",
    "    # --> LE = LE_e + LE_c = w_s*PM_s + w_c*PM_c\n",
    "    # --> PM_s = (delta*A + (rho*Cp*VPD - delta*ras*(A - A_s))/(raa + ras))/(delta + Psy*(1 + rss/(raa + ras)))\n",
    "    # --> PM_c = (delta*A + (rho*Cp*VPD - delta*rac*A_s)/(raa + rac))/(delta + Psy*(1 + rsc/(raa + rac)))\n",
    "    # --> w_s = 1/(1 + R_s*R_a/(R_c*(R_s + R_a)))\n",
    "    # --> w_c = 1/(1 + R_c*R_a/(R_s*(R_c + R_a)))\n",
    "    # --> R_s = (delta + Psy)*ras + Psy*rss\n",
    "    # --> R_c = (delta + Psy)*rac + Psy*rsc\n",
    "    # --> R_a = (delta + Psy)*raa\n",
    "    \n",
    "    # --> A = Rn - G\n",
    "    # --> A_s = Rns - G\n",
    "    # --> Rns = Rn*exp(-Kr*LAI)\n",
    "    #----- END ----\n",
    "\n",
    "    Kr = 0.6\n",
    "    A = auxi[25,:] - auxi[26,:]\n",
    "    Rns = auxi[25,:]*np.exp(-Kr*auxi[27,:])\n",
    "    A_s = Rns - auxi[26,:]\n",
    "    delta = auxi[17,:]\n",
    "    rho = auxi[18,:]\n",
    "    Cp = auxi[20,:]\n",
    "    Psy = auxi[19,:]\n",
    "    VPD = auxi[28,:]/10   # Check the units (should be in kPa)\n",
    "    ras = auxi[21,:]\n",
    "    rac = auxi[22,:]\n",
    "    raa = auxi[23,:]\n",
    "    rss = auxi[16,:]\n",
    "    PM_s = (delta*A + (rho*Cp*VPD - delta*ras*(A - A_s))/(raa + ras))/(delta + Psy*(1 + rss/(raa + ras)))\n",
    "    rsc = np.exp(rsc_pre)  # y = log(rsc)\n",
    "    rsc = np.clip(rsc,1e-5,5000)\n",
    "    PM_c = (delta*A + (rho*Cp*VPD - delta*rac*A_s)/(raa + rac))/(delta + Psy*(1 + rsc/(raa + rac)))\n",
    "    R_s = (delta + Psy)*ras + Psy*rss\n",
    "    R_c = (delta + Psy)*rac + Psy*rsc\n",
    "    R_a = (delta + Psy)*raa\n",
    "    w_s = 1/(1 + R_s*R_a/(R_c*(R_s + R_a)))\n",
    "    w_c = 1/(1 + R_c*R_a/(R_s*(R_c + R_a)))\n",
    "    \n",
    "    T_pre = w_c*PM_c\n",
    "    LE_pre = w_s*PM_s + w_c*PM_c\n",
    "    \n",
    "    return LE_pre\n",
    "\n",
    "# SW_model_T: calculate the T (Transpiration) using Shutteleworth-Wallace model given rsc and other input variable\n",
    "def SW_model_T_np(auxi, rsc_pre):\n",
    "    \n",
    "    #---- SW-Model ----\n",
    "    # --> LE = LE_e + LE_c = w_s*PM_s + w_c*PM_c\n",
    "    # --> PM_s = (delta*A + (rho*Cp*VPD - delta*ras*(A - A_s))/(raa + ras))/(delta + Psy*(1 + rss/(raa + ras)))\n",
    "    # --> PM_c = (delta*A + (rho*Cp*VPD - delta*rac*A_s)/(raa + rac))/(delta + Psy*(1 + rsc/(raa + rac)))\n",
    "    # --> w_s = 1/(1 + R_s*R_a/(R_c*(R_s + R_a)))\n",
    "    # --> w_c = 1/(1 + R_c*R_a/(R_s*(R_c + R_a)))\n",
    "    # --> R_s = (delta + Psy)*ras + Psy*rss\n",
    "    # --> R_c = (delta + Psy)*rac + Psy*rsc\n",
    "    # --> R_a = (delta + Psy)*raa\n",
    "    \n",
    "    # --> A = Rn - G\n",
    "    # --> A_s = Rns - G\n",
    "    # --> Rns = Rn*exp(-Kr*LAI)\n",
    "    #----- END ----\n",
    "\n",
    "    Kr = 0.6\n",
    "    A = auxi[25,:] - auxi[26,:]\n",
    "    Rns = auxi[25,:]*np.exp(-Kr*auxi[27,:])\n",
    "    A_s = Rns - auxi[26,:]\n",
    "    delta = auxi[17,:]\n",
    "    rho = auxi[18,:]\n",
    "    Cp = auxi[20,:]\n",
    "    Psy = auxi[19,:]\n",
    "    VPD = auxi[28,:]/10   # Check the units (should be in kPa)\n",
    "    ras = auxi[21,:]\n",
    "    rac = auxi[22,:]\n",
    "    raa = auxi[23,:]\n",
    "    rss = auxi[16,:]\n",
    "    PM_s = (delta*A + (rho*Cp*VPD - delta*ras*(A - A_s))/(raa + ras))/(delta + Psy*(1 + rss/(raa + ras)))\n",
    "    rsc = np.exp(rsc_pre)  # y = log(rsc)\n",
    "    rsc = np.clip(rsc,1e-5,5000)\n",
    "    PM_c = (delta*A + (rho*Cp*VPD - delta*rac*A_s)/(raa + rac))/(delta + Psy*(1 + rsc/(raa + rac)))\n",
    "    R_s = (delta + Psy)*ras + Psy*rss\n",
    "    R_c = (delta + Psy)*rac + Psy*rsc\n",
    "    R_a = (delta + Psy)*raa\n",
    "    w_s = 1/(1 + R_s*R_a/(R_c*(R_s + R_a)))\n",
    "    w_c = 1/(1 + R_c*R_a/(R_s*(R_c + R_a)))\n",
    "    \n",
    "    \n",
    "    T_pre = w_c*PM_c\n",
    "    LE_pre = w_s*PM_s + w_c*PM_c\n",
    "    \n",
    "    return T_pre\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "942f66cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0-rc1\n",
      "2.12.0-rc1\n",
      "----.DS_St----\n",
      "----AR-SLu----\n",
      "Data preparation Done!\n",
      "----AT-Neu----\n",
      "Data preparation Done!\n",
      "----AU-ASM----\n",
      "Data preparation Done!\n",
      "----AU-Cpr----\n",
      "Data preparation Done!\n",
      "----AU-Cum----\n",
      "Data preparation Done!\n",
      "----AU-DaP----\n",
      "Data preparation Done!\n",
      "----AU-DaS----\n",
      "Data preparation Done!\n",
      "----AU-Dry----\n",
      "Data preparation Done!\n",
      "----AU-Emr----\n",
      "Data preparation Done!\n",
      "----AU-GWW----\n",
      "Data preparation Done!\n",
      "----AU-Gin----\n",
      "Data preparation Done!\n",
      "----AU-How----\n",
      "Data preparation Done!\n",
      "----AU-Rig----\n",
      "Data preparation Done!\n",
      "----AU-Stp----\n",
      "Data preparation Done!\n",
      "----AU-TTE----\n",
      "Data preparation Done!\n",
      "----AU-Tum----\n",
      "Data preparation Done!\n",
      "----AU-Ync----\n",
      "Data preparation Done!\n",
      "----BE-Lon----\n",
      "Data preparation Done!\n",
      "----BE-Vie----\n",
      "Data preparation Done!\n",
      "----BR-Sa3----\n",
      "Data preparation Done!\n",
      "----CA-NS1----\n",
      "----CA-NS2----\n",
      "----CA-NS4----\n",
      "----CA-NS5----\n",
      "----CA-NS6----\n",
      "----CA-NS7----\n",
      "----CA-Qfo----\n",
      "Data preparation Done!\n",
      "----CA-SF1----\n",
      "Data preparation Done!\n",
      "----CA-SF2----\n",
      "Data preparation Done!\n",
      "----CA-SF3----\n",
      "Data preparation Done!\n",
      "----CH-Cha----\n",
      "Data preparation Done!\n",
      "----CH-Dav----\n",
      "Data preparation Done!\n",
      "----CH-Fru----\n",
      "Data preparation Done!\n",
      "----CH-Oe1----\n",
      "----CN-Cha----\n",
      "----CN-Cng----\n",
      "Data preparation Done!\n",
      "----CN-Dan----\n",
      "----CN-Din----\n",
      "----CN-Du2----\n",
      "----CN-HaM----\n",
      "Data preparation Done!\n",
      "----CN-Qia----\n",
      "----DE-Geb----\n",
      "Data preparation Done!\n",
      "----DE-Gri----\n",
      "Data preparation Done!\n",
      "----DE-Hai----\n",
      "Data preparation Done!\n",
      "----DE-Kli----\n",
      "Data preparation Done!\n",
      "----DE-Obe----\n",
      "Data preparation Done!\n",
      "----DE-Seh----\n",
      "Data preparation Done!\n",
      "----DE-Tha----\n",
      "Data preparation Done!\n",
      "----ES-LgS----\n",
      "Data preparation Done!\n",
      "----FI-Hyy----\n",
      "Data preparation Done!\n",
      "----FI-Sod----\n",
      "Data preparation Done!\n",
      "----FR-Gri----\n",
      "Data preparation Done!\n",
      "----FR-LBr----\n",
      "Data preparation Done!\n",
      "----GF-Guy----\n",
      "----IT-BCi----\n",
      "Data preparation Done!\n",
      "----IT-CA1----\n",
      "Data preparation Done!\n",
      "----IT-CA2----\n",
      "Data preparation Done!\n",
      "----IT-CA3----\n",
      "Data preparation Done!\n",
      "----IT-Col----\n",
      "Data preparation Done!\n",
      "----IT-Cpz----\n",
      "Data preparation Done!\n",
      "----IT-Isp----\n",
      "Data preparation Done!\n",
      "----IT-Lav----\n",
      "Data preparation Done!\n",
      "----IT-MBo----\n",
      "Data preparation Done!\n",
      "----IT-Noe----\n",
      "Data preparation Done!\n",
      "----IT-PT1----\n",
      "Data preparation Done!\n",
      "----IT-Ren----\n",
      "Data preparation Done!\n",
      "----IT-Ro1----\n",
      "----IT-Ro2----\n",
      "Data preparation Done!\n",
      "----IT-SR2----\n",
      "Data preparation Done!\n",
      "----IT-SRo----\n",
      "Data preparation Done!\n",
      "----NL-Loo----\n",
      "Data preparation Done!\n",
      "----RU-Fyo----\n",
      "Data preparation Done!\n",
      "----SD-Dem----\n",
      "Data preparation Done!\n",
      "----US-AR1----\n",
      "Data preparation Done!\n",
      "----US-AR2----\n",
      "Data preparation Done!\n",
      "----US-ARM----\n",
      "Data preparation Done!\n",
      "----US-Blo----\n",
      "Data preparation Done!\n",
      "----US-Cop----\n",
      "Data preparation Done!\n",
      "----US-GLE----\n",
      "Data preparation Done!\n",
      "----US-Goo----\n",
      "Data preparation Done!\n",
      "----US-KS2----\n",
      "Data preparation Done!\n",
      "----US-MMS----\n",
      "Data preparation Done!\n",
      "----US-Me2----\n",
      "Data preparation Done!\n",
      "----US-Me4----\n",
      "----US-Me6----\n",
      "Data preparation Done!\n",
      "----US-NR1----\n",
      "Data preparation Done!\n",
      "----US-Ne1----\n",
      "Data preparation Done!\n",
      "----US-Ne2----\n",
      "Data preparation Done!\n",
      "----US-Ne3----\n",
      "Data preparation Done!\n",
      "----US-SRG----\n",
      "Data preparation Done!\n",
      "----US-SRM----\n",
      "Data preparation Done!\n",
      "----US-Syv----\n",
      "Data preparation Done!\n",
      "----US-Ton----\n",
      "Data preparation Done!\n",
      "----US-UMB----\n",
      "----US-Var----\n",
      "Data preparation Done!\n",
      "----US-WCr----\n",
      "Data preparation Done!\n",
      "----US-Whs----\n",
      "Data preparation Done!\n",
      "----US-Wkg----\n",
      "Data preparation Done!\n",
      "----ZA-Kru----\n",
      "Data preparation Done!\n",
      "----ZM-Mon----\n",
      "Data preparation Done!\n"
     ]
    }
   ],
   "source": [
    "#pip install tensorflow --upgrade\n",
    "from my_functions_upgraded import *\n",
    "import gc\n",
    "import mpl_scatter_density\n",
    "import math\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.disable_eager_execution()\n",
    "print(tf.__version__)\n",
    "import matplotlib\n",
    "# matplotlib.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy import optimize\n",
    "from scipy.optimize import fsolve\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import datetime\n",
    "import matplotlib.dates as mdate\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import numpy.ma as ma\n",
    "import pickle\n",
    "#---- Basic settings ----\n",
    "sites = os.listdir('../../Input_Data/FluxData/')\n",
    "sites = [x[0:6] for x in sites]\n",
    "sites = np.unique(sites)\n",
    "sites.sort()\n",
    "#sites = sites[1:2]\n",
    "opt_hyp_params_info = pd.read_csv('Docs/hyperparameters.csv')\n",
    "\n",
    "var_names_long = ['DateTime','TA_F_MDS','SW_IN_F_MDS','fPAR','VPD_F_MDS','WS','RH','CO2_F_MDS','LAI','NETRAD','G_F_MDS',\\\n",
    "                  'hc','USTAR','GPP_NT_VUT_REF','theta','theta_2','LE_F_MDS','LE_c','H_F_MDS','H_c','QCflag', 'T_ET_TEA',\\\n",
    "                  'T_ET_uWUE','T_ET_uWUE_BC','LE_SW_emp_calib_LE','Tr_SW_emp_calib_LE','LE_SW_emp_calib_with_TEA',\\\n",
    "                  'Tr_SW_emp_calib_with_TEA','LE_SW_emp_calib_with_uWUE','Tr_SW_emp_calib_with_uWUE',\\\n",
    "                  'LE_SW_emp_calib_with_Liuyang','Tr_SW_emp_calib_with_Liuyang',\n",
    "                  'rss', 'delta','rou', 'Psy', 'Cp', 'ras', 'rac', 'raa', 'T_ET_Liuyang_2022',\\\n",
    "                 'LE_SW_hydr_calib_LE','Tr_SW_hydr_calib_LE',\\\n",
    "                   'LE_SW_hydr_calib_with_TEA','Tr_SW_hydr_calib_with_TEA','LE_SW_hydr_calib_with_uWUE',\\\n",
    "                   'Tr_SW_hydr_calib_with_uWUE','LE_SW_hydr_calib_with_Liuyang','Tr_SW_hydr_calib_with_Liuyang']\n",
    "var_names_short = ['DateTime','TA','SRad','fPAR','VPD','WS','RH','CO2','LAI','Rn','G','hc','USTAR','GPP','theta','theta_2','LE','LE_c','H',\\\n",
    "                   'H_c','QCflag','T_ET_TEA','T_ET_uWUE','T_ET_uWUE_BC','LE_SW_emp_calib_LE','Tr_SW_emp_calib_LE',\\\n",
    "                   'LE_SW_emp_calib_with_TEA','Tr_SW_emp_calib_with_TEA','LE_SW_emp_calib_with_uWUE','Tr_SW_emp_calib_with_uWUE',\\\n",
    "                   'LE_SW_emp_calib_with_Liuyang','Tr_SW_emp_calib_with_Liuyang',\\\n",
    "                   'rss', 'delta','rou', 'Psy', 'Cp',\\\n",
    "                   'ras','rac', 'raa', 'T_ET_Liuyang_2022','LE_SW_hydr_calib_LE','Tr_SW_hydr_calib_LE',\\\n",
    "                   'LE_SW_hydr_calib_with_TEA','Tr_SW_hydr_calib_with_TEA','LE_SW_hydr_calib_with_uWUE',\\\n",
    "                   'Tr_SW_hydr_calib_with_uWUE','LE_SW_hydr_calib_with_Liuyang','Tr_SW_hydr_calib_with_Liuyang']\n",
    "X_vars = ['Rn','G','TA','SRad','fPAR','USTAR','VPD','WS','CO2','LAI','theta'] # X variables for ML model\n",
    "Y_var = ['LE']       # Target for ML\n",
    "Auxi_Vars = ['LE','LE_c','H','H_c','QCflag','T_ET_TEA','T_ET_uWUE','T_ET_uWUE_BC',\\\n",
    "             'LE_SW_emp_calib_LE','Tr_SW_emp_calib_LE','LE_SW_emp_calib_with_TEA','Tr_SW_emp_calib_with_TEA',\\\n",
    "             'LE_SW_emp_calib_with_uWUE','Tr_SW_emp_calib_with_uWUE',\\\n",
    "             'LE_SW_emp_calib_with_Liuyang','Tr_SW_emp_calib_with_Liuyang',\\\n",
    "             'rss','delta','rou','Psy','Cp','ras','rac','raa','T_ET_Liuyang_2022','Rn','G','LAI','VPD',\\\n",
    "            'LE_SW_hydr_calib_LE','Tr_SW_hydr_calib_LE',\\\n",
    "                   'LE_SW_hydr_calib_with_TEA','Tr_SW_hydr_calib_with_TEA','LE_SW_hydr_calib_with_uWUE',\\\n",
    "                   'Tr_SW_hydr_calib_with_uWUE','LE_SW_hydr_calib_with_Liuyang','Tr_SW_hydr_calib_with_Liuyang'] # Additional variables\n",
    "\n",
    "for site in sites:\n",
    "    print(\"----\" + site + \"----\")\n",
    "    try:\n",
    "        #----Import Data (Prepare data for model training and validation----\n",
    "        X_train_temp = pd.read_csv('../../Input_Data/Train_Val_Data/X_train_temp_'+site+'.csv')\n",
    "        X_val_temp = pd.read_csv('../../Input_Data/Train_Val_Data/X_val_temp_'+site+'.csv')\n",
    "        Y_train = pd.read_csv('../../Input_Data/Train_Val_Data/Y_train_'+site+'.csv')\n",
    "        Y_val = pd.read_csv('../../Input_Data/Train_Val_Data/Y_val_'+site+'.csv')\n",
    "        \n",
    "        X_train = X_train_temp[X_vars]\n",
    "        X_val = X_val_temp[X_vars]\n",
    "        X_auxi_train = X_train_temp[Auxi_Vars]\n",
    "        X_auxi_val = X_val_temp[Auxi_Vars]\n",
    "        # Backup dataframe\n",
    "        X_train_back = X_train\n",
    "        X_val_back = X_val\n",
    "        X_test = X_val\n",
    "        Y_test = Y_val\n",
    "        Y_train = np.asarray(Y_train.T)\n",
    "        Y_val = np.asarray(Y_val.T)\n",
    "        Y_test = np.asarray(Y_test.T)\n",
    "        X_train = np.asarray(X_train.T)\n",
    "        X_val = np.asarray(X_val.T)\n",
    "        X_test = np.asarray(X_test.T)\n",
    "        # ----- Normalization of the Input Data ----\n",
    "        #var_names = {'TA','SRad','VPD','WS','RH','CO2','LAI','Rn','G','GPP','SM'}\n",
    "        # Normalization\n",
    "        mean = X_train.T.astype('float').mean(axis=0)\n",
    "        std = X_train.T.astype('float').std(axis=0)\n",
    "        X_train = ((X_train.T - mean) / std).T\n",
    "        X_val = ((X_val.T - mean) / std).T\n",
    "        X_test  = ((X_test.T - mean) / std).T\n",
    "        \n",
    "        X_train[8,:][np.isnan(X_train[8,:])] = 0  # CO2\n",
    "        X_val[8,:][np.isnan(X_val[8,:])] = 0  # CO2\n",
    "        X_test[8,:][np.isnan(X_test[8,:])] = 0  # CO2\n",
    "\n",
    "        X_auxi_train = np.asarray(X_auxi_train.T)\n",
    "        X_auxi_val = np.asarray(X_auxi_val.T)\n",
    "        X_auxi_test = X_auxi_val\n",
    "        print('Data preparation Done!')\n",
    "        #------------------ ML model training-------------------------------------\n",
    "        # Basic settings\n",
    "        learning_rate = 0.001\n",
    "        minibatch_size = 64\n",
    "        print_cost = True\n",
    "        num_epochs = opt_hyp_params_info['epoch'][opt_hyp_params_info['Site']==site].item()\n",
    "        n_hidden = opt_hyp_params_info['n_hidden'][opt_hyp_params_info['Site']==site].item()\n",
    "        n_neurons = opt_hyp_params_info['n_neuron'][opt_hyp_params_info['Site']==site].item()\n",
    "\n",
    "        # Load parameters from saved pickle file\n",
    "        parameters = pickle.load(open('Trained_parameters/' + site + '_trained_ANN_params.pkl', 'rb'))\n",
    "        #---- Prediction ----(Training)   \n",
    "        rsc_pred_train = predict_tuning(X_train,n_hidden, parameters)[0]\n",
    "        LE_pred_train = SW_model_LE_np(X_auxi_train.astype('float'), rsc_pred_train.astype('float'))\n",
    "        T_pred_train = SW_model_T_np(X_auxi_train.astype('float'), rsc_pred_train.astype('float'))\n",
    "\n",
    "        \n",
    "        \n",
    "        #---- Prediction ----(Validation)   \n",
    "        rsc_pred_val = predict_tuning(X_val,n_hidden, parameters)[0]\n",
    "        LE_pred_val = SW_model_LE_np(X_auxi_val.astype('float'), rsc_pred_val.astype('float'))\n",
    "        T_pred_val = SW_model_T_np(X_auxi_val.astype('float'), rsc_pred_val.astype('float'))       \n",
    "\n",
    "        X_train_temp['LE_pred'] = LE_pred_train\n",
    "        X_val_temp['LE_pred'] = LE_pred_val\n",
    "        X_train_temp['T_pred'] = T_pred_train\n",
    "        X_val_temp['T_pred'] = T_pred_val\n",
    "        X_train_temp['rsc'] = np.exp(rsc_pred_train)\n",
    "        X_val_temp['rsc'] = np.exp(rsc_pred_val)\n",
    "        \n",
    "        X_train_temp['Period'] = \"Train\"\n",
    "        X_val_temp['Period'] = \"Val\"\n",
    "        \n",
    "        X_train_temp.to_csv('Predictions/Train_predictions_' + site + '.csv', index=False)\n",
    "        X_val_temp.to_csv('Predictions/Val_predictions_' + site + '.csv', index=False)\n",
    "        X_all = pd.concat([X_train_temp, X_val_temp])\n",
    "        X_all.to_csv('Predictions/All_predictions_' + site + '.csv', index=False)\n",
    "    except (OSError,ValueError):\n",
    "        pass\n",
    "         "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1538b69f",
   "metadata": {},
   "source": [
    "# "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
